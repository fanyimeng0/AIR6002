{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7, Parts (c)-(e): Stochastic Gradient Descent Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we visualize how SGD works. This visualization corresponds to parts (c)-(e) of question 7 in Assignment 1.\n",
    "\n",
    "Use this notebook to write your code for problem 7 parts (c)-(e) by filling in the sections marked `# TODO` and running all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from sgd_helper import (\n",
    "    generate_dataset1,\n",
    "    generate_dataset2,\n",
    "    plot_dataset,\n",
    "    plot_loss_function,\n",
    "    animate_convergence,\n",
    "    animate_sgd_suite\n",
    ")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7(c): Implementation of SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the loss, gradient, and SGD functions according to the guidelines given in the problem statement in order to perform SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, Y, w):\n",
    "    '''\n",
    "    Calculate the squared loss function.\n",
    "    \n",
    "    Inputs:\n",
    "        X: A (N, D) shaped numpy array containing the data points.\n",
    "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "        w: A (D, ) shaped numpy array containing the weight vector.\n",
    "    \n",
    "    Outputs:\n",
    "        The loss evaluated with respect to X, Y, and w.\n",
    "    '''\n",
    "    \n",
    "    #==============================================\n",
    "    # TODO: Implement the SGD loss function.\n",
    "    #==============================================\n",
    "\n",
    "def gradient(x, y, w):\n",
    "    '''\n",
    "    Calculate the gradient of the loss function with respect to\n",
    "    a single point (x, y), and using weight vector w.\n",
    "    \n",
    "    Inputs:\n",
    "        x: A (D, ) shaped numpy array containing a single data point.\n",
    "        y: The float label for the data point.\n",
    "        w: A (D, ) shaped numpy array containing the weight vector.\n",
    "        \n",
    "    Output:\n",
    "        The gradient of the loss with respect to x, y, and w. \n",
    "    '''\n",
    "\n",
    "    #==============================================\n",
    "    # TODO: Implement the gradient of the\n",
    "    # loss function.\n",
    "    #==============================================    \n",
    "    \n",
    "\n",
    "def SGD(X, Y, w_start, eta, N_epochs):\n",
    "    '''\n",
    "    Perform SGD using dataset (X, Y), initial weight vector w_start,\n",
    "    learning rate eta, and N_epochs epochs.\n",
    "    \n",
    "    Inputs:\n",
    "        X: A (N, D) shaped numpy array containing the data points.\n",
    "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
    "        w_start:  A (D, ) shaped numpy array containing the weight vector initialization.\n",
    "        eta: The step size.\n",
    "        N_epochs: The number of epochs (iterations) to run SGD.\n",
    "        \n",
    "    Outputs:\n",
    "        W: A (N_epochs, D) shaped array containing the weight vectors from all iterations.\n",
    "        losses: A (N_epochs, ) shaped array containing the losses from all iterations.\n",
    "    '''\n",
    "    \n",
    "    #==============================================\n",
    "    # TODO: Implement the SGD algorithm.\n",
    "    #==============================================    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7(d): Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start off by generating two simple 2-dimensional datasets. For simplicity we do not consider separate training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X1, Y1 = generate_dataset1()\n",
    "plot_dataset(X1, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_start = [0.01, 0.01]\n",
    "eta = 0.00001\n",
    "N_epochs = 2000\n",
    "W, losses = SGD(X1, Y1, w_start, eta, N_epochs)\n",
    "print (W[1,])\n",
    "print (W[1999,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.linalg.inv(X1.T.dot(X1)).dot(X1.T).dot(Y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X2, Y2 = generate_dataset2()\n",
    "plot_dataset(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_start = [0.01, 0.01]\n",
    "eta = 0.00001\n",
    "N_epochs = 2000\n",
    "W, losses = SGD(X2, Y2, w_start, eta, N_epochs)\n",
    "print (W[1,])\n",
    "print (W[1999,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the analytical result\n",
    "print (np.linalg.inv(X2.T.dot(X2)).dot(X2.T).dot(Y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD from a single point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's visualize SGD from a single starting point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "# <FR> changes the animation speed.\n",
    "params = ({'w_start': [0.01, 0.01], 'eta': 0.00001},)\n",
    "N_epochs = 1000\n",
    "FR = 20\n",
    "\n",
    "# Let's animate it!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view how the weights change as the algorithm converges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "params = ({'w_start': [0.01, 0.01], 'eta': 0.00001},)\n",
    "N_epochs = 1000\n",
    "FR = 20\n",
    "\n",
    "# Let's do it!\n",
    "W, _ = SGD(X1, Y1, params[0]['w_start'], params[0]['eta'], N_epochs)\n",
    "anim = animate_convergence(X1, Y1, W, FR)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD from multiple points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize SGD from multiple arbitrary starting points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "# Here, we specify each different set of initializations as a dictionary.\n",
    "params = (\n",
    "    {'w_start': [-0.8, -0.3], 'eta': 0.00001},\n",
    "    {'w_start': [-0.9, 0.4], 'eta': 0.00001},\n",
    "    {'w_start': [-0.4, 0.9], 'eta': 0.00001},\n",
    "    {'w_start': [0.8, 0.8], 'eta': 0.00001},\n",
    ")\n",
    "N_epochs = 1000\n",
    "FR = 20\n",
    "\n",
    "# Let's go!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same thing but with a different dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "params = (\n",
    "    {'w_start': [-0.8, -0.3], 'eta': 0.00001},\n",
    "    {'w_start': [-0.9, 0.4], 'eta': 0.00001},\n",
    "    {'w_start': [-0.4, 0.9], 'eta': 0.00001},\n",
    "    {'w_start': [0.8, 0.8], 'eta': 0.00001},\n",
    ")\n",
    "N_epochs = 1000\n",
    "FR = 20\n",
    "\n",
    "# Animate!\n",
    "anim = animate_sgd_suite(SGD, loss, X2, Y2, params, N_epochs, FR)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7(e): SGD with different step sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize SGD with different step sizes (eta):\n",
    "\n",
    "(For ease of visualization: the trajectories are ordered from left to right by increasing eta value. Also, note that we use smaller values of N_epochs and FR here for easier visualization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "params = (\n",
    "    {'w_start': [0.7, 0.8], 'eta': 0.00001},\n",
    "    { 'w_start': [0.2, 0.8], 'eta': 0.00005},\n",
    "    {'w_start': [-0.2, 0.7], 'eta': 0.0001},\n",
    "    {'w_start': [-0.6, 0.6], 'eta': 0.0002},\n",
    ")\n",
    "N_epochs = 100\n",
    "FR = 2\n",
    "\n",
    "# Go!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR, ms=2)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting SGD Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the difference in convergence rates a different way. Plot the loss with respect to epoch (iteration) number for each value of eta on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Plotting SGD convergence'''\n",
    "\n",
    "#==============================================\n",
    "# TODO: For the given learning rates, plot the \n",
    "# loss for each epoch.\n",
    "#=============================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, a big step size results in fast convergence! Why don't we just set eta to a really big value, then? Say, eta=1?\n",
    "\n",
    "(Again, note that the FR is lower for this animation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "params = ({'w_start': [0.01, 0.01], 'eta': 1},)\n",
    "N_epochs = 100\n",
    "FR = 2\n",
    "\n",
    "# Voila!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR, ms=2)\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's try eta=10 as well. What happens? (Hint: look at W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to feed the SGD.\n",
    "w_start = [0.01, 0.01]\n",
    "eta = 10\n",
    "N_epochs = 100\n",
    "\n",
    "# Presto!\n",
    "W, losses = SGD(X1, Y1, w_start, eta, N_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Visualization (not part of the homework problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final visualization! What happens if the loss function has multiple optima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import different SGD & loss functions.\n",
    "# In particular, the loss function has multiple optima.\n",
    "from sgd_multiopt_helper import SGD, loss\n",
    "\n",
    "# Parameters to feed the SGD.\n",
    "params = (\n",
    "    {'w_start': [0.9, 0.9], 'eta': 0.01},\n",
    "    { 'w_start': [0.0, 0.0], 'eta': 0.01},\n",
    "    {'w_start': [-0.8, 0.6], 'eta': 0.01},\n",
    "    {'w_start': [-0.8, -0.6], 'eta': 0.01},\n",
    "    {'w_start': [-0.4, -0.3], 'eta': 0.01},\n",
    ")\n",
    "N_epochs = 100\n",
    "FR = 2\n",
    "\n",
    "# One more time!\n",
    "anim = animate_sgd_suite(SGD, loss, X1, Y1, params, N_epochs, FR, ms=2)\n",
    "HTML(anim.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
